{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinct-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "result=[]\n",
    "def search(dirname):\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1]\n",
    "                if ext == '.jpg': \n",
    "                    #print(full_filename)\n",
    "                    result.append(full_filename)\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "search(\"/home/lab/dataset/skin_dataset/sfa_nonskin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "figured-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "test_result=[]\n",
    "for i in range(len(result)):\n",
    "    img = cv2.imread(result[i])\n",
    "    for j in range(len(img)-3):\n",
    "        for k in range(len(img[0])-3):\n",
    "            make_data=img[j:j+3,k:k+3]\n",
    "            test_result.append(make_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hundred-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_result=np.array(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "commercial-repeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095640, 3, 3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-people",
   "metadata": {},
   "source": [
    "# Under 3x3 Matrix, Print image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lonely-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result)):\n",
    "    img = cv2.imread(result[i])\n",
    "    if (img.shape[0]<=3) or (img.shape[1]<=3):\n",
    "        print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "automatic-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "result1=[]\n",
    "def search(dirname):\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1]\n",
    "                if ext == '.jpg': \n",
    "                    #print(full_filename)\n",
    "                    result1.append(full_filename)\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "search(\"/home/lab/dataset/skin_dataset/sfa_skin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "earlier-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result1)):\n",
    "    img = cv2.imread(result1[i])\n",
    "    if (img.shape[0]<=3) or (img.shape[1]<=3):\n",
    "        print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supported-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result1=[]\n",
    "for i in range(len(result1)):\n",
    "    img = cv2.imread(result1[i])\n",
    "    for j in range(len(img)-3):\n",
    "        for k in range(len(img[0])-3):\n",
    "            make_data=img[j:j+3,k:k+3]\n",
    "            test_result1.append(make_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prime-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result1=np.array(test_result1)\n",
    "test_result=np.array(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "middle-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YCbCrTransform(x):\n",
    "    #================= exponancial function ==================#\n",
    "    exponancial=[[65.738, 129.057, 25.064],\n",
    "                 [-37.945, -74.494, 112.439],\n",
    "                 [112.439, -94.154, -18.285]]\n",
    "    exponancial=np.matrix(exponancial)\n",
    "    exponancial=(1/256)*exponancial\n",
    "    \n",
    "    A=[[16],[128],[128]]\n",
    "    A=np.matrix(A)\n",
    "    #=========================================================#\n",
    "    x=np.matrix(x)\n",
    "    x=np.transpose(x)\n",
    "    Answer=A+exponancial*x\n",
    "    Answer=np.array(Answer)\n",
    "    Answer=Answer.tolist()\n",
    "    Cb=Answer[1][0]\n",
    "    Cr=Answer[2][0]\n",
    "    \n",
    "    return Cb,Cr\n",
    "def Make_redemention(x):\n",
    "    before_result=[]\n",
    "    #tot_sum=0\n",
    "    for i in tqdm(range(x.shape[0])):    #x.shape[0]\n",
    "        before_result1=[]\n",
    "        time.sleep(0.0000001)\n",
    "        for j in range(x.shape[1]):\n",
    "            before_result2=[]\n",
    "            for k in range(x.shape[2]):\n",
    "                before_result3=[]\n",
    "                before=x[i][j][k]\n",
    "                Cb,Cr=YCbCrTransform(before)\n",
    "                before_result3.append(before[0])\n",
    "                before_result3.append(before[1])\n",
    "                before_result3.append(before[2])\n",
    "                before_result3.append(Cb)\n",
    "                before_result3.append(Cr)\n",
    "                before_result2.append(before_result3)\n",
    "            before_result1.append(before_result2)\n",
    "        before_result.append(before_result1)\n",
    "        #tot_sum+=i\n",
    "        #print(tot_sum)\n",
    "    return before_result\n",
    "def reshape_demension(x):\n",
    "    make_result=[]\n",
    "    for i in tqdm(range(x.shape[0])):\n",
    "        time.sleep(0.0000001)\n",
    "        make_result1=[]\n",
    "        for j in range(x.shape[1]):\n",
    "            for k in range(x.shape[2]):\n",
    "                make_result1.append(x[i][j][k])\n",
    "        make_result.append(make_result1)\n",
    "    return make_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-government",
   "metadata": {},
   "source": [
    "# CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stainless-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm import trange\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pacific-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1095640/1095640 [06:51<00:00, 2662.41it/s]\n",
      "100%|██████████| 657384/657384 [04:06<00:00, 2671.22it/s]\n"
     ]
    }
   ],
   "source": [
    "AAA=Make_redemention(test_result)\n",
    "BBB=Make_redemention(test_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "instant-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA=np.array(AAA,dtype=np.uint8)\n",
    "BBB=np.array(BBB,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "crazy-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1095640/1095640 [01:10<00:00, 15645.70it/s]\n",
      "100%|██████████| 657384/657384 [00:41<00:00, 15706.27it/s]\n"
     ]
    }
   ],
   "source": [
    "AAA1=reshape_demension(AAA)\n",
    "BBB1=reshape_demension(BBB)\n",
    "AAA1=np.array(AAA1,dtype=np.uint8)\n",
    "BBB1=np.array(BBB1,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "electronic-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA1=np.array(AAA1,dtype=np.uint8)\n",
    "BBB1=np.array(BBB1,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "freelance-jersey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 66,  86, 103, 138, 118],\n",
       "       [ 66,  86, 103, 138, 118],\n",
       "       [ 71,  91, 108, 138, 118],\n",
       "       [ 75,  95, 113, 138, 117],\n",
       "       [ 74,  94, 112, 138, 117],\n",
       "       [ 74,  92, 109, 138, 118],\n",
       "       [ 74,  94, 111, 138, 118],\n",
       "       [ 74,  92, 109, 138, 118],\n",
       "       [ 69,  86, 105, 138, 119]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAA1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-judgment",
   "metadata": {},
   "source": [
    "# Save SFA => npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "binding-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"SFA_Filter_NS\",AAA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fluid-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"SFA_Filter_S\",BBB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opened-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA1= (AAA1*(1/256)-0.5)/0.5\n",
    "BBB1= (BBB1*(1/256)-0.5)/0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-windsor",
   "metadata": {},
   "source": [
    "# Make Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "seven-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "for i in range(len(AAA1)+len(BBB1)):\n",
    "    if i>len(AAA1):\n",
    "        label.append(0)\n",
    "    else:\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "significant-acrobat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753024"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-hungarian",
   "metadata": {},
   "source": [
    "# Put together data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "retired-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=[]\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        for j in range(len(AAA1)):\n",
    "            input_data.append(AAA1[j])\n",
    "    else :\n",
    "        for j in range(len(BBB1)):\n",
    "            input_data.append(BBB1[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "suffering-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753024"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "available-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.array(label)\n",
    "input_data=np.array(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adult-receiver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1753024,), (1753024, 9, 5))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape, input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "completed-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy # Add Deepcopy for args\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "input_data=torch.FloatTensor(input_data)\n",
    "label=torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worldwide-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "banner-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset,testset=torch.utils.data.random_split(dataset,[1403024,350000])\n",
    "partition={'train':trainset,'test':testset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "informed-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "class test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test,self).__init__()\n",
    "        A = [[1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "             [1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "             [0 ,1, 1, 0, 1, 1, 0, 0, 0],\n",
    "             [1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
    "             [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "             [0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
    "             [0, 0, 0, 1, 1, 0, 1, 1, 0],\n",
    "             [0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
    "             [0, 0, 0, 0, 1, 1, 0, 1, 1]]\n",
    "        adj=torch.FloatTensor(A)\n",
    "        adj=adj.cuda()\n",
    "        self.adj=adj\n",
    "        self.W= nn.Parameter(torch.detach(torch.rand(5,48)).requires_grad_(True))\n",
    "        self.act = nn.Sigmoid()\n",
    "        self.Linear=nn.Linear(432,10)\n",
    "        self.Linear1=nn.Linear(10,2)\n",
    "#ReLU 쓰니까 out 이 2번째에서 다 0값이 나옴.\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = torch.matmul(x,self.W)\n",
    "        out = torch.matmul(self.adj,out)\n",
    "        out = out.view(-1,432)\n",
    "        out = self.Linear(out)\n",
    "        out = self.act(out)\n",
    "        out = self.Linear1(out)\n",
    "        #out=F.softmax(out,dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "variable-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,partition,optimizer,creiterion):\n",
    "    trainloader = torch.utils.data.DataLoader(partition['train'],\n",
    "                                             batch_size=4096,\n",
    "                                             shuffle=True)\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    total =0\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(trainloader, 0)):\n",
    "        time.sleep(0.0000001)\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #if i % 200 == 0:\n",
    "        #    print(correct,train_loss)\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return net, train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "domestic-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(net, partition, args):\n",
    "    testloader = torch.utils.data.DataLoader(partition['test'], \n",
    "                                             batch_size=4096, \n",
    "                                             shuffle=True, num_workers=2)\n",
    "    net.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(testloader):\n",
    "            time.sleep(0.0000001)\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "alike-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:10<00:00, 31.89it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 50.21it/s]\n",
      "  0%|          | 1/343 [00:00<00:45,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 12.47, train_loss : 0.26, train_acc : 90.65,test_acc : 93.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 28.20it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 51.31it/s]\n",
      "  1%|          | 2/343 [00:00<00:18, 18.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 13.84, train_loss : 0.16, train_acc : 94.41,test_acc : 95.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 28.06it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 50.93it/s]\n",
      "  1%|          | 2/343 [00:00<00:18, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 13.92, train_loss : 0.13, train_acc : 95.62,test_acc : 95.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 28.10it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 52.20it/s]\n",
      "  1%|          | 2/343 [00:00<00:19, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 13.86, train_loss : 0.12, train_acc : 95.82,test_acc : 95.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 27.94it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 50.65it/s]\n",
      "  1%|          | 2/343 [00:00<00:27, 12.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 13.98, train_loss : 0.12, train_acc : 96.03,test_acc : 96.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 27.80it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 48.08it/s]\n",
      "  1%|          | 2/343 [00:00<00:19, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 14.13, train_loss : 0.11, train_acc : 96.17,test_acc : 96.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 27.08it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 50.89it/s]\n",
      "  1%|          | 2/343 [00:00<00:21, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 14.36, train_loss : 0.11, train_acc : 96.26,test_acc : 96.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 27.04it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 49.87it/s]\n",
      "  0%|          | 1/343 [00:00<00:35,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 14.41, train_loss : 0.11, train_acc : 96.37,test_acc : 96.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 27.67it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 49.04it/s]\n",
      "  1%|          | 2/343 [00:00<00:27, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 14.15, train_loss : 0.10, train_acc : 96.43,test_acc : 96.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:12<00:00, 27.06it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 45.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 14.56, train_loss : 0.10, train_acc : 96.50,test_acc : 96.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = test()\n",
    "net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0015, weight_decay=0.00001)\n",
    "train_losses=[]\n",
    "val_accs=[]\n",
    "for epoch in range(10):\n",
    "    ts=time.time()\n",
    "    net, train_loss,train_acc=train(net, partition, optimizer, criterion)\n",
    "    test_acc = test1(net,partition,criterion)\n",
    "    te=time.time()\n",
    "    print('time : {:2.2f}, train_loss : {:2.2f}, train_acc : {:2.2f},test_acc : {:2.2f}'.format(te-ts,train_loss,train_acc,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-dealing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
