{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "leading-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "result=[]\n",
    "def search(dirname):\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1]\n",
    "                if ext == '.jpg': \n",
    "                    #print(full_filename)\n",
    "                    result.append(full_filename)\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "search(\"/home/lab/dataset/skin_dataset/sfa_nonskin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rough-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "test_result=[]\n",
    "for i in range(100):\n",
    "    img = cv2.imread(result[i])\n",
    "    for j in range(len(img)-3):\n",
    "        for k in range(len(img[0])-3):\n",
    "            make_data=img[j:j+3,k:k+3]\n",
    "            test_result.append(make_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "understanding-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_result=np.array(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "angry-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "result1=[]\n",
    "def search(dirname):\n",
    "    try:\n",
    "        filenames = os.listdir(dirname)\n",
    "        for filename in filenames:\n",
    "            full_filename = os.path.join(dirname, filename)\n",
    "            if os.path.isdir(full_filename):\n",
    "                search(full_filename)\n",
    "            else:\n",
    "                ext = os.path.splitext(full_filename)[-1]\n",
    "                if ext == '.jpg': \n",
    "                    #print(full_filename)\n",
    "                    result1.append(full_filename)\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "search(\"/home/lab/dataset/skin_dataset/sfa_skin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suited-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result1=[]\n",
    "for i in range(100):\n",
    "    img = cv2.imread(result1[i])\n",
    "    for j in range(len(img)-3):\n",
    "        for k in range(len(img[0])-3):\n",
    "            make_data=img[j:j+3,k:k+3]\n",
    "            test_result1.append(make_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sonic-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result1=np.array(test_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "designing-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YCbCrTransform(x):\n",
    "    #================= exponancial function ==================#\n",
    "    exponancial=[[65.738, 129.057, 25.064],\n",
    "                 [-37.945, -74.494, 112.439],\n",
    "                 [112.439, -94.154, -18.285]]\n",
    "    exponancial=np.matrix(exponancial)\n",
    "    exponancial=(1/256)*exponancial\n",
    "    \n",
    "    A=[[16],[128],[128]]\n",
    "    A=np.matrix(A)\n",
    "    #=========================================================#\n",
    "    x=np.matrix(x)\n",
    "    x=np.transpose(x)\n",
    "    Answer=A+exponancial*x\n",
    "    Answer=np.array(Answer)\n",
    "    Answer=Answer.tolist()\n",
    "    Cb=Answer[1][0]\n",
    "    Cr=Answer[2][0]\n",
    "    \n",
    "    return Cb,Cr\n",
    "def Make_redemention(x):\n",
    "    before_result=[]\n",
    "    for i in range(x.shape[0]):    #x.shape[0]\n",
    "        before_result1=[]\n",
    "        for j in range(x.shape[1]):\n",
    "            before_result2=[]\n",
    "            for k in range(x.shape[2]):\n",
    "                before_result3=[]\n",
    "                before=x[i][j][k]\n",
    "                Cb,Cr=YCbCrTransform(before)\n",
    "                before_result3.append(before[0])\n",
    "                before_result3.append(before[1])\n",
    "                before_result3.append(before[2])\n",
    "                before_result3.append(Cb)\n",
    "                before_result3.append(Cr)\n",
    "                before_result2.append(before_result3)\n",
    "            before_result1.append(before_result2)\n",
    "        before_result.append(before_result1)\n",
    "    return before_result\n",
    "def reshape_demension(x):\n",
    "    make_result=[]\n",
    "    for i in range(x.shape[0]):\n",
    "        make_result1=[]\n",
    "        for j in range(x.shape[1]):\n",
    "            for k in range(x.shape[2]):\n",
    "                make_result1.append(x[i][j][k])\n",
    "        make_result.append(make_result1)\n",
    "    return make_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "balanced-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA=Make_redemention(test_result)\n",
    "BBB=Make_redemention(test_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "experienced-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA=np.array(AAA,dtype=np.uint8)\n",
    "BBB=np.array(BBB,dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sealed-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA1=reshape_demension(AAA)\n",
    "BBB1=reshape_demension(BBB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cheap-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA1=np.array(AAA1)\n",
    "BBB1=np.array(BBB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "valuable-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA1= (AAA1*(1/256)-0.5)/0.5 #non-skin\n",
    "BBB1= (BBB1*(1/256)-0.5)/0.5 #Skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "banner-battery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03125  ,  0.4453125,  0.9609375,  0.296875 , -0.25     ],\n",
       "       [-0.0390625,  0.4375   ,  0.96875  ,  0.296875 , -0.25     ],\n",
       "       [-0.015625 ,  0.4609375,  0.9921875,  0.296875 , -0.25     ],\n",
       "       [-0.0078125,  0.46875  ,  0.984375 ,  0.296875 , -0.25     ],\n",
       "       [-0.03125  ,  0.4453125,  0.9609375,  0.296875 , -0.25     ],\n",
       "       [-0.0234375,  0.453125 ,  0.96875  ,  0.296875 , -0.25     ],\n",
       "       [ 0.0078125,  0.484375 ,  0.9921875,  0.2890625, -0.25     ],\n",
       "       [ 0.       ,  0.4765625,  0.9765625,  0.2890625, -0.25     ],\n",
       "       [ 0.015625 ,  0.4921875,  0.9921875,  0.2890625, -0.25     ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BBB1[15355]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "guilty-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA1.shape, BBB1.shape\n",
    "label=[]\n",
    "for i in range(39200):\n",
    "    if i >19599:\n",
    "        label.append(0)\n",
    "    else :\n",
    "        label.append(1)\n",
    "input_data=[]\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        for j in range(len(AAA1)):\n",
    "            input_data.append(AAA1[j])\n",
    "    else :\n",
    "        for j in range(len(BBB1)):\n",
    "            input_data.append(BBB1[j])\n",
    "input_data=np.array(input_data)\n",
    "label=np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "nuclear-earthquake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39200, 9, 5), (39200,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excess-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy # Add Deepcopy for args\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "humanitarian-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data=torch.FloatTensor(input_data)\n",
    "label=torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "liked-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "dataset = TensorDataset(input_data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "finite-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset,testset=torch.utils.data.random_split(dataset,[31360,7840])\n",
    "partition={'train':trainset,'test':testset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "distinct-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy # Add Deepcopy for args\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excess-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "class test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test,self).__init__()\n",
    "        A = [[1, 1, 0, 1, 1, 0, 0, 0, 0],\n",
    "             [1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
    "             [0 ,1, 1, 0, 1, 1, 0, 0, 0],\n",
    "             [1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
    "             [1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "             [0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
    "             [0, 0, 0, 1, 1, 0, 1, 1, 0],\n",
    "             [0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
    "             [0, 0, 0, 0, 1, 1, 0, 1, 1]]\n",
    "        adj=torch.FloatTensor(A)\n",
    "        adj=adj.cuda()\n",
    "        self.adj=adj\n",
    "        self.W= nn.Parameter(torch.detach(torch.rand(5,48)).requires_grad_(True))\n",
    "        self.act = nn.Sigmoid()\n",
    "        self.Linear=nn.Linear(432,10)\n",
    "        self.Linear1=nn.Linear(10,2)\n",
    "#ReLU 쓰니까 out 이 2번째에서 다 0값이 나옴.\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = torch.matmul(x,self.W)\n",
    "        out = torch.matmul(self.adj,out)\n",
    "        out = out.view(-1,432)\n",
    "        out = self.Linear(out)\n",
    "        out = self.act(out)\n",
    "        out = self.Linear1(out)\n",
    "        #out=F.softmax(out,dim=1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "major-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,partition,optimizer,creiterion):\n",
    "    trainloader = torch.utils.data.DataLoader(partition['train'],\n",
    "                                             batch_size=256,\n",
    "                                             shuffle=True)\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    total =0\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #if i % 200 == 0:\n",
    "        #    print(correct,train_loss)\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    train_acc = 100 * correct / total\n",
    "    return net, train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "descending-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(net, partition, args):\n",
    "    testloader = torch.utils.data.DataLoader(partition['test'], \n",
    "                                             batch_size=256, \n",
    "                                             shuffle=True, num_workers=2)\n",
    "    net.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_acc = 100 * correct / total\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-baghdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time : 0.50, train_loss : 0.41, train_acc : 85.47,test_acc : 88.06\n",
      "time : 0.51, train_loss : 0.29, train_acc : 89.08,test_acc : 89.30\n",
      "time : 0.49, train_loss : 0.25, train_acc : 90.15,test_acc : 92.54\n",
      "time : 0.52, train_loss : 0.23, train_acc : 92.11,test_acc : 92.40\n",
      "time : 0.48, train_loss : 0.21, train_acc : 92.37,test_acc : 91.52\n",
      "time : 0.54, train_loss : 0.19, train_acc : 92.63,test_acc : 91.49\n",
      "time : 0.49, train_loss : 0.18, train_acc : 92.61,test_acc : 91.86\n",
      "time : 0.50, train_loss : 0.18, train_acc : 92.49,test_acc : 91.93\n",
      "time : 0.50, train_loss : 0.17, train_acc : 92.77,test_acc : 92.63\n",
      "time : 0.49, train_loss : 0.17, train_acc : 92.89,test_acc : 92.26\n",
      "time : 0.48, train_loss : 0.16, train_acc : 92.66,test_acc : 92.44\n",
      "time : 0.54, train_loss : 0.16, train_acc : 92.91,test_acc : 92.21\n",
      "time : 0.51, train_loss : 0.16, train_acc : 93.06,test_acc : 92.56\n",
      "time : 0.50, train_loss : 0.15, train_acc : 93.01,test_acc : 93.20\n",
      "time : 0.48, train_loss : 0.15, train_acc : 93.23,test_acc : 93.41\n",
      "time : 0.51, train_loss : 0.15, train_acc : 93.25,test_acc : 92.78\n",
      "time : 0.52, train_loss : 0.15, train_acc : 93.25,test_acc : 93.04\n",
      "time : 0.55, train_loss : 0.14, train_acc : 93.27,test_acc : 92.87\n",
      "time : 0.49, train_loss : 0.14, train_acc : 93.27,test_acc : 92.96\n",
      "time : 0.49, train_loss : 0.14, train_acc : 93.37,test_acc : 93.18\n",
      "time : 0.50, train_loss : 0.14, train_acc : 93.30,test_acc : 93.14\n",
      "time : 0.48, train_loss : 0.14, train_acc : 93.42,test_acc : 93.15\n",
      "time : 0.52, train_loss : 0.14, train_acc : 93.47,test_acc : 93.21\n",
      "time : 0.55, train_loss : 0.14, train_acc : 93.52,test_acc : 93.44\n",
      "time : 0.50, train_loss : 0.14, train_acc : 93.47,test_acc : 93.38\n",
      "time : 0.50, train_loss : 0.14, train_acc : 93.57,test_acc : 93.32\n",
      "time : 0.48, train_loss : 0.14, train_acc : 93.62,test_acc : 93.38\n",
      "time : 0.51, train_loss : 0.14, train_acc : 93.62,test_acc : 93.43\n",
      "time : 0.51, train_loss : 0.14, train_acc : 93.63,test_acc : 93.57\n",
      "time : 0.56, train_loss : 0.14, train_acc : 93.67,test_acc : 93.67\n",
      "time : 0.49, train_loss : 0.14, train_acc : 93.73,test_acc : 93.51\n",
      "time : 0.51, train_loss : 0.14, train_acc : 93.79,test_acc : 93.46\n",
      "time : 0.50, train_loss : 0.14, train_acc : 93.74,test_acc : 93.41\n",
      "time : 0.49, train_loss : 0.13, train_acc : 93.77,test_acc : 93.78\n",
      "time : 0.49, train_loss : 0.13, train_acc : 93.81,test_acc : 93.94\n",
      "time : 0.53, train_loss : 0.13, train_acc : 93.81,test_acc : 93.42\n",
      "time : 0.48, train_loss : 0.13, train_acc : 93.97,test_acc : 93.90\n",
      "time : 0.48, train_loss : 0.13, train_acc : 93.91,test_acc : 93.72\n",
      "time : 0.51, train_loss : 0.13, train_acc : 94.18,test_acc : 93.75\n",
      "time : 0.49, train_loss : 0.13, train_acc : 94.10,test_acc : 93.61\n",
      "time : 0.50, train_loss : 0.13, train_acc : 94.47,test_acc : 94.26\n",
      "time : 0.55, train_loss : 0.13, train_acc : 94.48,test_acc : 93.60\n",
      "time : 0.55, train_loss : 0.13, train_acc : 94.43,test_acc : 94.41\n",
      "time : 0.52, train_loss : 0.12, train_acc : 94.60,test_acc : 94.13\n",
      "time : 0.51, train_loss : 0.12, train_acc : 94.53,test_acc : 94.21\n",
      "time : 0.49, train_loss : 0.12, train_acc : 94.55,test_acc : 94.26\n",
      "time : 0.50, train_loss : 0.12, train_acc : 94.60,test_acc : 94.18\n",
      "time : 0.50, train_loss : 0.12, train_acc : 94.37,test_acc : 93.93\n",
      "time : 0.54, train_loss : 0.12, train_acc : 94.43,test_acc : 94.20\n",
      "time : 0.50, train_loss : 0.12, train_acc : 94.61,test_acc : 94.55\n"
     ]
    }
   ],
   "source": [
    "net = test()\n",
    "net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0015, weight_decay=0.00001)\n",
    "train_losses=[]\n",
    "val_accs=[]\n",
    "for epoch in range(200):\n",
    "    ts=time.time()\n",
    "    net, train_loss,train_acc=train(net, partition, optimizer, criterion)\n",
    "    test_acc = test1(net,partition,criterion)\n",
    "    te=time.time()\n",
    "    print('time : {:2.2f}, train_loss : {:2.2f}, train_acc : {:2.2f},test_acc : {:2.2f}'.format(te-ts,train_loss,train_acc,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "anticipated-onion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-venice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
